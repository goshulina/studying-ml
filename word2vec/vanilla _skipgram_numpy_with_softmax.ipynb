{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://aegis4048.github.io/demystifying_neural_network_in_skip_gram_language_modeling#eq-9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 100/500000 [00:05<6:58:48, 19.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# open('/Users/georgychernousov/Downloads/example.txt','r')\n",
    "with open('reviews.txt','r') as f:\n",
    "    reviews = f.readlines()\n",
    "    \n",
    "# __init__\n",
    "tokens = ' '.join(reviews).split()[:500000]\n",
    "vocab = list(set(tokens))\n",
    "batch_size = 100\n",
    "hidden_size = 100\n",
    "learning_rate = 0.01\n",
    "window = 1\n",
    "X, y = [], []\n",
    "w_input = (np.random.rand(len(vocab),hidden_size))#  * 0.001\n",
    "w_output = (np.random.rand(hidden_size,len(vocab)))# * 0.001\n",
    "\n",
    "def encode_one_hot(x, vocab_size):\n",
    "    one_hots = []\n",
    "    for i in x:\n",
    "        zeros = np.zeros([vocab_size, 1])\n",
    "        zeros[i] = 1\n",
    "        one_hots.append(zeros)\n",
    "    return one_hots\n",
    "\n",
    "def softmax(x):\n",
    "    return np.divide(np.exp(x), np.sum(np.exp(x), axis=0, keepdims=True) + 0.001)\n",
    "\n",
    "fallten = lambda x: np.array([item for sublist in x for item in sublist])\n",
    "\n",
    "for word_i in tqdm(range(len(tokens))):\n",
    "    target_word = vocab.index(tokens[word_i])\n",
    "    y_indexes = [*list(range(max(0,word_i-window), word_i)), \n",
    "        *list(range(word_i+1, min(len(tokens),word_i+window+1)))\n",
    "        ]\n",
    "    y.append(y_indexes)\n",
    "    X.append([target_word] * len(y_indexes))\n",
    "    \n",
    "    if word_i % batch_size == 0 and word_i != 0:\n",
    "        one_hots = encode_one_hot(fallten(X), len(vocab))\n",
    "        # forward prop\n",
    "        preds = []\n",
    "        l_1s = []\n",
    "        for x in one_hots:\n",
    "            l_1 = np.dot(x.reshape(1, -1), w_input)\n",
    "            l_1s.append(l_1)\n",
    "            # softmax\n",
    "            l_2 = np.dot(l_1, w_output)\n",
    "            y_pred = softmax(l_2)\n",
    "            preds.append(y_pred)\n",
    "        \n",
    "        # back prop\n",
    "        pred_index = 0\n",
    "        preds_to_sum = []\n",
    "        y_trues_to_sum = []\n",
    "        for y_true in y:\n",
    "            y_trues = encode_one_hot(np.array(y_true), len(vocab))\n",
    "            y_trues = [y_true.reshape(1, -1) for y_true in y_trues]\n",
    "            y_trues_to_sum.append(y_trues)\n",
    "            preds_to_sum.append(preds[pred_index:len(y_true)+pred_index])\n",
    "            pred_index += len(y_true)\n",
    "        sum_errors = []\n",
    "        for i in range(len(y)):\n",
    "            sum_error = sum(preds_to_sum[i]) - sum(y_trues_to_sum[i])\n",
    "            sum_errors.append(sum_error)\n",
    "        grad_w_inputs = []\n",
    "        grad_w_outputs = []\n",
    "        for n, sum_error in enumerate(sum_errors):\n",
    "            grad_w_inputs.append(\n",
    "                np.dot(encode_one_hot(X[n], len(vocab))[0], \n",
    "                       np.dot(w_output, \n",
    "                              sum_error.reshape(-1, 1)).T\n",
    "                      )\n",
    "            )\n",
    "            grad_w_outputs.append(\n",
    "                np.dot(\n",
    "                    l_1.reshape(-1, 1),\n",
    "                    sum_error\n",
    "                )\n",
    "            )\n",
    "        # update\n",
    "        for i in range(len(y)):\n",
    "            w_input -= learning_rate * grad_w_inputs[i]\n",
    "            w_output -= learning_rate * grad_w_outputs[i]\n",
    "        X, y = [], []\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
